{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cbxGw4HcD5e3LpJQmdXoMIU96cTPRZum",
      "authorship_tag": "ABX9TyM6BM5OfxlqQw8Tu5Q69iVa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rihemmaarefe/TextClassifierObjSubj/blob/main/TextClassifierObjSubj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install streamlit==0.84.0"
      ],
      "metadata": {
        "id": "iu7AUvoPnoZL"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade pip"
      ],
      "metadata": {
        "id": "nm4B9GFxoeXK"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install git+https://github.com/whitews/session-state.git"
      ],
      "metadata": {
        "id": "lYyq87mhpdBC"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade streamlit"
      ],
      "metadata": {
        "id": "r3b4f6XptHJ8"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install altair"
      ],
      "metadata": {
        "id": "7od5K3Xk2Nl-"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py"
      ],
      "metadata": {
        "id": "-b36biIemr10"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install session-state==0.2.3"
      ],
      "metadata": {
        "id": "89H2MgvatT5I"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py"
      ],
      "metadata": {
        "id": "8Z6NFqdx4i1E"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd \n",
        "import sqlite3\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "import matplotlib.pyplot as plt\n",
        "import altair as alt\n",
        "\n",
        "# Load the data \n",
        "data = pd.read_csv('/content/drive/MyDrive/Stage/trainData.csv') \n",
        "X = data['meaning'] \n",
        "y = data['category']\n",
        "\n",
        "# Preprocess the data using the CountVectorizer \n",
        "vectorizer = CountVectorizer(stop_words='english') \n",
        "X_counts = vectorizer.fit_transform(X) \n",
        "\n",
        "# Train a machine learning model \n",
        "model = MultinomialNB() \n",
        "model.fit(X_counts, y) \n",
        "\n",
        "# Define a function to predict the category of new text \n",
        "def predict_category(text):\n",
        "    text_counts = vectorizer.transform([text])\n",
        "    prediction = model.predict(text_counts)\n",
        "    probabilities = model.predict_proba(text_counts)[0]\n",
        "    return prediction[0],probabilities\n",
        "\n",
        "# Define a function to plot the probabilities of each category \n",
        "def plot_probabilities(text):\n",
        "    text_counts = vectorizer.transform([text])\n",
        "    probabilities = model.predict_proba(text_counts)[0]\n",
        "    categories = model.classes_\n",
        "    fig, ax = plt.subplots(figsize=(6, 2))\n",
        "    ax.bar(df_proba['label'], df_proba['probability'])\n",
        "    ax.set_xlabel('Category')\n",
        "    ax.set_ylabel('Probability')\n",
        "    ax.set_title('Category Probabilities')\n",
        "    for i, prob in enumerate(df_proba['probability']):\n",
        "      ax.text(i, prob + 0.05, f\"{prob*100:.2f}%\", ha='center')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "# Define the SessionState class to store the dataframe\n",
        "class SessionState:\n",
        "    def __init__(self):\n",
        "        self.results_df = pd.DataFrame(columns=['text_input', 'predicted_label'])\n",
        "\n",
        "# Create the Streamlit app and initialize the SessionState object\n",
        "st.title('Objective vs. Subjective Text Classifier')\n",
        "state = SessionState()\n",
        "\n",
        "# Connect to the database\n",
        "conn = sqlite3.connect('results.db')\n",
        "c = conn.cursor()\n",
        "\n",
        "# Create a table for the results if it doesn't exist\n",
        "c.execute('''CREATE TABLE IF NOT EXISTS results\n",
        "             (text_input TEXT, predicted_label TEXT)''')\n",
        "             \n",
        "# Add a text input and a submit button\n",
        "text_input = st.text_input('Enter some text:')\n",
        "if st.button('Submit'):\n",
        "    # Predict the category and store the input and output data in the dataframe\n",
        "    prediction, probabilities = predict_category(text_input)\n",
        "    state.results_df = state.results_df.append({'text_input': text_input, 'predicted_label': prediction}, ignore_index=True)\n",
        "    \n",
        "    # Insert the results into the database\n",
        "    c.execute(\"INSERT INTO results VALUES (?, ?)\", (text_input, prediction))\n",
        "    conn.commit()\n",
        "    \n",
        "    # Plot the probabilities of each category\n",
        "    # plot_probabilities(text_input)\n",
        "\n",
        "    st.success(\"Data Submitted\")\n",
        "    \n",
        "    res_col1 ,res_col2 = st.columns(2)\n",
        "    with res_col1:\n",
        "      st.info(\"Prediction\")\n",
        "      st.write(prediction)\n",
        "\n",
        "    with res_col2:\n",
        "      st.info(\"Probability\")\n",
        "      #  plot\n",
        "      categories, probabilities = zip(*sorted(zip(model.classes_, probabilities), key=lambda x: x[1], reverse=True))\n",
        "      df_proba = pd.DataFrame({'label': categories, 'probability': probabilities})\n",
        "\n",
        "      # visz\n",
        "      fig = alt.Chart(df_proba).mark_bar().encode(x='label',y='probability')\n",
        "      st.altair_chart(fig,use_container_width=True)\t\n",
        "\n",
        "\n",
        "# Fetch the results from the database and display them in a table\n",
        "c.execute(\"SELECT * FROM results\")\n",
        "results = c.fetchall()\n",
        "results_df = pd.DataFrame(results, columns=['text_input', 'predicted_label'])\n",
        "st.write(results_df)\n",
        "st.write('made by Rihem Maaref')\n",
        "\n",
        "# Close the database connection\n",
        "conn.close()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELn3dmIaxm4f",
        "outputId": "fd8cdc15-a091-4ae6-d9cc-494a193786ab"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKNTnVh6KSK6",
        "outputId": "f1706a5b-bfa5-4bea-d225-4af44b0a6e57"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\tdata.db  drive\tlogs.txt  results.csv  results.db  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "t96_qBduKcGA"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgw_kVGjKdcG",
        "outputId": "2b9032c2-2fc4-4d55-a08b-a74707e36ffb"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.711s\n",
            "your url is: https://giant-wings-remain-34-82-151-153.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0FvKDnQ_zFjC"
      },
      "execution_count": 177,
      "outputs": []
    }
  ]
}